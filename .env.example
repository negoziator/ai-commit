# AI-Commit Environment Variables
# Copy this file to .env or .env.local depending on your use case
#
# For CLI usage:
#   cp .env.example .env
#   # Edit .env with your credentials
#   aicommit
#
# For testing:
#   cp .env.example .env.local
#   # Edit .env.local with your test credentials
#   npm test
#
# Note: Both .env and .env.local are gitignored

# ============================================
# Provider Selection
# ============================================
# Choose your LLM provider: openai, anthropic, azure-openai, ollama, custom
# provider=openai

# ============================================
# OpenAI Configuration
# ============================================
# OPENAI_KEY=sk-...

# ============================================
# Anthropic Configuration
# ============================================
# provider=anthropic
# ANTHROPIC_KEY=sk-ant-...

# ============================================
# Azure OpenAI Configuration
# ============================================
# provider=azure-openai
# AZURE_OPENAI_KEY=your-key
# AZURE_ENDPOINT=https://your-resource.openai.azure.com

# ============================================
# Ollama Configuration (Local)
# ============================================
# provider=ollama
# OLLAMA_ENDPOINT=http://localhost:11434
# model=llama3.2

# ============================================
# Custom/RAG Configuration
# ============================================
# provider=custom
# CUSTOM_ENDPOINT=https://your-endpoint.com/api
# CUSTOM_KEY=optional-auth-key

# ============================================
# General Configuration
# ============================================
# model=gpt-4o-mini
# locale=en
# generate=1
# max-length=50
# type=conventional
# auto-confirm=false
# prepend-reference=false
# temperature=0.2
# max-completion-tokens=10000
# timeout=10000
# proxy=http://proxy.example.com:8080
